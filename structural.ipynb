{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchprofile import profile_macs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# helper functions to measure latency of a regular PyTorch models.\n",
    "#   Unlike fine-grained pruning, channel pruning\n",
    "#   can directly leads to model size reduction and speed up.\n",
    "@torch.no_grad()\n",
    "def measure_latency(model, dummy_input, n_warmup=20, n_test=100):\n",
    "    model.eval()\n",
    "    # warmup\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model(dummy_input)\n",
    "    # real test\n",
    "    t1 = time.time()\n",
    "    for _ in range(n_test):\n",
    "        _ = model(dummy_input)\n",
    "    t2 = time.time()\n",
    "    return (t2 - t1) / n_test  # average latency\n",
    "\n",
    "def get_model_macs(model, inputs) -> int:\n",
    "    return profile_macs(model, inputs)\n",
    "\n",
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeNet5 model definition\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(weights, indices, dim=0):\n",
    "    things = []\n",
    "    for index,i in enumerate(weights): \n",
    "        if index in indices:\n",
    "            if dim>=1:\n",
    "                things.append(torch.tensor(i).tolist())\n",
    "            else:\n",
    "                things.append(torch.tensor(i).item())\n",
    "    return torch.tensor(things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(model, loader):\n",
    "    dummy_input,_ = next(iter(loader))\n",
    "    model = model.to('cpu')\n",
    "\n",
    "    size = get_model_size(model=model, count_nonzero_only=True)/(8*2**10)\n",
    "\n",
    "    latency = measure_latency(model, dummy_input)\n",
    "\n",
    "    macs = get_model_macs(model, dummy_input)\n",
    "\n",
    "    param = get_num_parameters(model)\n",
    "\n",
    "    accuracy = evaluate(model,loader)\n",
    "    \n",
    "    return size.item(), latency, param, macs, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables and model\n",
    "batch_size=64\n",
    "def dataset():\n",
    "    train_data = datasets.MNIST('./data/mnist', train=True, download=True,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ]))\n",
    "    test_data = datasets.MNIST('./data/mnist', train=False, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize((32,32)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1325,), (0.3105,))\n",
    "                               ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "train_loader, test_loader = dataset()\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "model = torch.load(\"lenet5.pt\")\n",
    "model.eval()\n",
    "orig_weight_dict = model.state_dict().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  241.2109375 KB\n",
      "original_latency:  0.0036598777770996092\n",
      "macs:  27060736\n",
      "param:  61750\n",
      "accuracy:  95.59 %\n"
     ]
    }
   ],
   "source": [
    "orig_size, orig_latency, orig_param, orig_macs, orig_accuracy = measure(model,test_loader)\n",
    "print(\"size: \", orig_size, \"KB\")\n",
    "print(\"original_latency: \",orig_latency)\n",
    "print(\"macs: \",orig_macs)\n",
    "print(\"param: \",orig_param)\n",
    "print(\"accuracy: \",orig_accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/xzlv_l050l51pv993nmt4rpm0000gn/T/ipykernel_1723/1323181907.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  things.append(torch.tensor(i).tolist())\n",
      "/var/folders/n1/xzlv_l050l51pv993nmt4rpm0000gn/T/ipykernel_1723/1323181907.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  things.append(torch.tensor(i).item())\n"
     ]
    }
   ],
   "source": [
    "#Channel Pruning\n",
    "model = torch.load(\"prunedLenet5.pt\")\n",
    "channel_mask=[]\n",
    "\n",
    "conv=[]\n",
    "bns=[]\n",
    "fcs=[]\n",
    "\n",
    "for i in model.modules():\n",
    "    if isinstance(i, nn.Conv2d):\n",
    "        conv.append(i)\n",
    "    if isinstance(i, nn.BatchNorm2d):\n",
    "        bns.append(i)\n",
    "    if isinstance(i, nn.Linear):\n",
    "        fcs.append(i)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sparsity=0.7\n",
    "    mask_temp=[]\n",
    "    i=0\n",
    "    current_conv = conv[i]\n",
    "    current_bn = bns[i]\n",
    "    next_conv = conv[i+1] \n",
    "    original_channels = current_conv.weight\n",
    "    n_keep = round((1-sparsity)*len(original_channels))\n",
    "\n",
    "    mean_conv = torch.linalg.matrix_norm(current_conv.weight)\n",
    "    threshold_conv = torch.flatten(mean_conv).kthvalue(n_keep).values\n",
    "    \n",
    "    indices=[]\n",
    "    for index, i in enumerate(mean_conv):\n",
    "        if i<=threshold_conv:\n",
    "            indices.append(index)\n",
    "            mask_temp.append(torch.zeros(5,5))\n",
    "        else:\n",
    "            mask_temp.append(torch.ones(5,5))\n",
    "    channel_mask.append(mask_temp)\n",
    "    \n",
    "    current_conv.weight.set_(prune(current_conv.weight.detach(),indices,1))\n",
    "    current_conv.bias.set_(prune(current_conv.bias.detach(),indices))\n",
    "    current_bn.weight.set_(prune(current_bn.weight.detach(), indices))\n",
    "    current_bn.bias.set_(prune(current_bn.bias.detach(),indices))\n",
    "    current_bn.running_mean.set_(prune(current_bn.running_mean.detach(), indices))\n",
    "    current_bn.running_var.set_(prune(current_bn.running_var.detach(), indices))\n",
    "\n",
    "    things = []\n",
    "    for index,i in enumerate(next_conv.weight): \n",
    "        things.append(prune(i, indices,1).tolist())\n",
    "    things = torch.tensor(things)\n",
    "    next_conv.weight.set_(things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  118.54296875 KB\n",
      "original_latency:  0.0027092885971069336\n",
      "macs:  15467008\n",
      "param:  60466\n",
      "accuracy:  27.25 %\n",
      "Mask: [[tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]), tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]), tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])]]\n"
     ]
    }
   ],
   "source": [
    "prune_size, prune_latency, prune_param, prune_macs, prune_accuracy = measure(model,test_loader)\n",
    "print(\"size: \", prune_size, \"KB\")\n",
    "print(\"original_latency: \",prune_latency)\n",
    "print(\"macs: \",prune_macs)\n",
    "print(\"param: \",prune_param)\n",
    "print(\"accuracy: \",prune_accuracy,\"%\")\n",
    "print(\"Mask:\",channel_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
